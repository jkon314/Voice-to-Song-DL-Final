{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import soundfile as sf\n",
    "from Vocoder import Vocoder\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Assume the decoder's output is a list of spectrograms\n",
    "    # Replace this with the actual output from your decoder\n",
    "    n_fft = 1024\n",
    "    hop_length = 256\n",
    "    win_length = 1024\n",
    "    num_iters = 30\n",
    "\n",
    "    # dummy spectrograms (replace this with actual decoder outputs)\n",
    "    decoder_outputs = [torch.rand((513, 100)) for _ in range(3)]\n",
    "    \n",
    "    # Ensure the spectrograms are on the same device as the Vocoder\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    decoder_outputs = [spect.to(device) for spect in decoder_outputs]\n",
    "    \n",
    "    # Vocoder instance\n",
    "    vocoder = Vocoder(n_fft=n_fft, hop_length=hop_length, win_length=win_length, num_iters=num_iters)\n",
    "    \n",
    "    # Process each spectrogram\n",
    "    for i, decoder_output in enumerate(decoder_outputs):\n",
    "        # Reconstruct the time signal using Griffin-Lim algorithm\n",
    "        reconstructed_signal = vocoder.reconstruct(decoder_output)\n",
    "        \n",
    "        # Save or play the reconstructed signal\n",
    "        reconstructed_signal = reconstructed_signal.cpu().numpy()\n",
    "        sf.write(f'reconstructed_signal_{i}.wav', reconstructed_signal, samplerate=16000)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
