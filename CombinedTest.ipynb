{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/cs7643-finalproject/lib/python3.9/site-packages/torchtext/datasets/__init__.py:4: UserWarning: \n",
      "/!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \n",
      "Torchtext is deprecated and the last released version will be 0.18 (this one). You can silence this warning by calling the following at the beginnign of your scripts: `import torchtext; torchtext.disable_torchtext_deprecation_warning()`\n",
      "  warnings.warn(torchtext._TORCHTEXT_DEPRECATION_MSG)\n",
      "/opt/homebrew/anaconda3/envs/cs7643-finalproject/lib/python3.9/site-packages/torchtext/data/__init__.py:4: UserWarning: \n",
      "/!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \n",
      "Torchtext is deprecated and the last released version will be 0.18 (this one). You can silence this warning by calling the following at the beginnign of your scripts: `import torchtext; torchtext.disable_torchtext_deprecation_warning()`\n",
      "  warnings.warn(torchtext._TORCHTEXT_DEPRECATION_MSG)\n",
      "/opt/homebrew/anaconda3/envs/cs7643-finalproject/lib/python3.9/site-packages/torchtext/vocab/__init__.py:4: UserWarning: \n",
      "/!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \n",
      "Torchtext is deprecated and the last released version will be 0.18 (this one). You can silence this warning by calling the following at the beginnign of your scripts: `import torchtext; torchtext.disable_torchtext_deprecation_warning()`\n",
      "  warnings.warn(torchtext._TORCHTEXT_DEPRECATION_MSG)\n",
      "/opt/homebrew/anaconda3/envs/cs7643-finalproject/lib/python3.9/site-packages/torchtext/utils.py:4: UserWarning: \n",
      "/!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \n",
      "Torchtext is deprecated and the last released version will be 0.18 (this one). You can silence this warning by calling the following at the beginnign of your scripts: `import torchtext; torchtext.disable_torchtext_deprecation_warning()`\n",
      "  warnings.warn(torchtext._TORCHTEXT_DEPRECATION_MSG)\n"
     ]
    }
   ],
   "source": [
    "# Just run this block. Please do not modify the following code.\n",
    "import math\n",
    "import time\n",
    "import io\n",
    "import numpy as np\n",
    "import csv\n",
    "from IPython.display import Image\n",
    "\n",
    "# Pytorch package\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Torchtest package\n",
    "import torchtext\n",
    "from torchtext.datasets import Multi30k\n",
    "from torch.utils.data import DataLoader\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from collections import Counter\n",
    "from torchtext.vocab import vocab\n",
    "from torchtext.utils import download_from_url, extract_archive\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "# Tqdm progress bar\n",
    "from tqdm import tqdm_notebook, tqdm\n",
    "\n",
    "# Code provide to you for training and evaluation\n",
    "\n",
    "# for auto-reloading external modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "torch.seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are using device: mps\n"
     ]
    }
   ],
   "source": [
    "# Check device availability\n",
    "device = ''\n",
    "if torch.cuda.is_available():\n",
    "    device = 'cuda'\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = 'mps'\n",
    "else:\n",
    "    device = 'cpu'\n",
    "device = torch.device(device)\n",
    "print(\"You are using device: %s\" % device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_output = torch.rand((5, 320, 20)).to(device) # N, input_size, 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Decoder import Decoder\n",
    "from PostNet import PostNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 80, 20])\n",
      "tensor([[[-0.0074, -0.0202, -0.0404,  ..., -0.0122,  0.0116,  0.0369],\n",
      "         [-0.0391, -0.0675, -0.0440,  ..., -0.0482, -0.0408, -0.0310],\n",
      "         [-0.0471,  0.0003,  0.0272,  ..., -0.0253, -0.0217,  0.0309],\n",
      "         ...,\n",
      "         [-0.0411, -0.0500, -0.0412,  ..., -0.0170, -0.0244, -0.0423],\n",
      "         [ 0.0167, -0.0110,  0.0521,  ...,  0.0336,  0.0598,  0.0603],\n",
      "         [-0.0264, -0.0165, -0.0441,  ..., -0.0474, -0.0511,  0.0455]],\n",
      "\n",
      "        [[-0.0199, -0.0015, -0.0085,  ..., -0.0073,  0.0356,  0.0287],\n",
      "         [-0.0248, -0.0507, -0.0157,  ..., -0.0433, -0.0705, -0.0308],\n",
      "         [-0.0311, -0.0459, -0.0448,  ...,  0.0181, -0.0088,  0.0313],\n",
      "         ...,\n",
      "         [-0.0298, -0.0323,  0.0026,  ..., -0.0607, -0.0520, -0.0403],\n",
      "         [ 0.0357,  0.0347,  0.0352,  ..., -0.0047,  0.0305,  0.0717],\n",
      "         [ 0.0133,  0.0022,  0.0095,  ...,  0.0068,  0.0019,  0.0380]],\n",
      "\n",
      "        [[ 0.0125, -0.0015,  0.0147,  ...,  0.0093,  0.0306,  0.0324],\n",
      "         [ 0.0223, -0.0032, -0.0315,  ..., -0.0468, -0.0815, -0.0638],\n",
      "         [-0.0367, -0.0185, -0.0405,  ..., -0.0048, -0.0114,  0.0010],\n",
      "         ...,\n",
      "         [-0.0474, -0.0966, -0.0635,  ...,  0.0021, -0.0158, -0.0401],\n",
      "         [ 0.0120,  0.0331,  0.0268,  ...,  0.0282,  0.0675,  0.0311],\n",
      "         [ 0.0040,  0.0128, -0.0106,  ..., -0.0293, -0.0157,  0.0126]],\n",
      "\n",
      "        [[ 0.0158,  0.0113,  0.0346,  ...,  0.0685,  0.0714,  0.0111],\n",
      "         [-0.0130, -0.0409, -0.0255,  ..., -0.0070, -0.0542, -0.0321],\n",
      "         [-0.0714, -0.0566, -0.0448,  ..., -0.0375, -0.0028,  0.0164],\n",
      "         ...,\n",
      "         [-0.0529, -0.0638, -0.0148,  ..., -0.0460, -0.0359, -0.0625],\n",
      "         [ 0.0495,  0.0627,  0.0748,  ...,  0.0136,  0.0479,  0.0685],\n",
      "         [-0.0077, -0.0272, -0.0177,  ..., -0.0794, -0.0803,  0.0122]],\n",
      "\n",
      "        [[ 0.0107, -0.0003, -0.0012,  ...,  0.0250,  0.0917,  0.0695],\n",
      "         [-0.0159, -0.0669, -0.1049,  ..., -0.0064, -0.0270, -0.0265],\n",
      "         [-0.0386, -0.0409, -0.0061,  ..., -0.0403, -0.0473, -0.0209],\n",
      "         ...,\n",
      "         [-0.0341, -0.0751, -0.0934,  ..., -0.0761, -0.0527, -0.0201],\n",
      "         [ 0.0142,  0.0366,  0.0398,  ...,  0.0453,  0.0626,  0.0305],\n",
      "         [-0.0109,  0.0058,  0.0015,  ..., -0.0502, -0.0266,  0.0404]]],\n",
      "       device='mps:0', grad_fn=<TransposeBackward0>)\n"
     ]
    }
   ],
   "source": [
    "decoder = Decoder(lstm_bidirectional=True).to(device)\n",
    "decoder_output = decoder.forward(encoder_output)\n",
    "print(decoder_output.shape) # N, output_size, 1\n",
    "print(decoder_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 80, 20])\n",
      "tensor([[[ 0.4004,  0.3564,  0.0794,  ..., -0.2619, -0.1306, -0.1823],\n",
      "         [-0.3228, -0.5483,  0.0567,  ...,  0.3977,  0.0078,  0.0659],\n",
      "         [-0.1532, -0.3041, -0.4822,  ..., -0.1152, -0.3246, -0.6561],\n",
      "         ...,\n",
      "         [ 0.0990, -0.0151,  0.1652,  ..., -0.2176, -0.1653, -0.0551],\n",
      "         [ 0.1219,  0.2633,  0.4579,  ..., -0.3859,  0.3868,  0.0475],\n",
      "         [ 0.4893,  0.1749,  0.2055,  ...,  0.1346,  0.3933,  0.1470]],\n",
      "\n",
      "        [[-0.2078,  0.1908,  0.0227,  ..., -0.3803,  0.1928, -0.0802],\n",
      "         [-0.2858, -0.1520, -0.1230,  ...,  0.4037,  0.3054, -0.1552],\n",
      "         [-0.0607,  0.5977, -0.0547,  ..., -0.0456, -0.3878, -0.3753],\n",
      "         ...,\n",
      "         [ 0.3754,  0.2060,  0.6203,  ...,  0.0237,  0.2181,  0.5058],\n",
      "         [ 0.1301,  0.4488,  0.3396,  ..., -0.2713,  0.1827, -0.2259],\n",
      "         [-0.0623,  0.2255, -0.1077,  ..., -0.3112, -0.2637,  0.0159]],\n",
      "\n",
      "        [[ 0.4192,  0.3441,  0.5968,  ...,  0.1366, -0.0450,  0.0798],\n",
      "         [ 0.1129, -0.1094,  0.3387,  ...,  0.5000,  0.2545,  0.2545],\n",
      "         [-0.2902,  0.2088, -0.5317,  ...,  0.2222,  0.2875,  0.0307],\n",
      "         ...,\n",
      "         [ 0.0158,  0.3342,  0.2543,  ...,  0.2024,  0.1407, -0.1773],\n",
      "         [ 0.3218,  0.4593, -0.0128,  ..., -0.2181, -0.1186,  0.1989],\n",
      "         [ 0.1311,  0.3565, -0.1913,  ...,  0.5194,  0.3232, -0.2042]],\n",
      "\n",
      "        [[ 0.3980,  0.3599, -0.5669,  ...,  0.2113,  0.3562, -0.1502],\n",
      "         [ 0.2200,  0.3923,  0.5357,  ..., -0.7488, -0.4959, -0.1233],\n",
      "         [ 0.1451,  0.1694,  0.3577,  ...,  0.3619,  0.2069,  0.0878],\n",
      "         ...,\n",
      "         [ 0.2328,  0.0654, -0.0251,  ...,  0.7352,  0.6584,  0.3426],\n",
      "         [-0.2759, -0.0921, -0.0614,  ...,  0.2765, -0.1049,  0.2722],\n",
      "         [ 0.2874, -0.2071, -0.3459,  ...,  0.1858,  0.0011,  0.0936]],\n",
      "\n",
      "        [[ 0.0173,  0.3044,  0.0112,  ...,  0.0974, -0.0582, -0.1357],\n",
      "         [ 0.2566, -0.2772,  0.3452,  ..., -0.0372, -0.1914, -0.1859],\n",
      "         [ 0.0787,  0.4636, -0.6025,  ..., -0.2679,  0.0652,  0.1904],\n",
      "         ...,\n",
      "         [ 0.0135,  0.0159,  0.3059,  ..., -0.3449,  0.0765,  0.4114],\n",
      "         [-0.0729, -0.0887, -0.0878,  ...,  0.4433,  0.6621,  0.2539],\n",
      "         [ 0.1842, -0.1356,  0.1593,  ..., -0.2236,  0.2686,  0.0186]]],\n",
      "       device='mps:0', grad_fn=<ConvolutionBackward0>)\n"
     ]
    }
   ],
   "source": [
    "postnet = PostNet().to(device)\n",
    "postnet_output = postnet.forward(decoder_output)\n",
    "print(postnet_output.shape) # (N, output size, T)\n",
    "print(postnet_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/cs7643-finalproject/lib/python3.9/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([5, 80, 20])) that is different to the input size (torch.Size([5, 80, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.8126, device='mps:0', grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loss Test\n",
    "from utils import criterion\n",
    "\n",
    "input = torch.rand((5, 80, 1)).to(device)\n",
    "\n",
    "criterion(input=input, encoder_ouput=encoder_output, decoder_output=decoder_output, postnet_output=postnet_output, encoded_postnet_output=encoder_output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs7643-finalproject",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
