{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<function torch.random.seed() -> int>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Just run this block. Please do not modify the following code.\n",
    "import math\n",
    "import time\n",
    "import io\n",
    "import numpy as np\n",
    "import csv\n",
    "from IPython.display import Image\n",
    "\n",
    "# Pytorch package\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Torchtest package\n",
    "# import torchtext\n",
    "# from torchtext.datasets import Multi30k\n",
    "# from torch.utils.data import DataLoader\n",
    "# from torchtext.data.utils import get_tokenizer\n",
    "# from collections import Counter\n",
    "# from torchtext.vocab import vocab\n",
    "# from torchtext.utils import download_from_url, extract_archive\n",
    "# from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.optim import Adam\n",
    "\n",
    "# Tqdm progress bar\n",
    "from tqdm import tqdm_notebook, tqdm\n",
    "\n",
    "# Code provide to you for training and evaluation\n",
    "\n",
    "# for auto-reloading external modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "torch.seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are using device: mps\n"
     ]
    }
   ],
   "source": [
    "# Check device availability\n",
    "device = ''\n",
    "if torch.cuda.is_available():\n",
    "    device = 'cuda'\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = 'mps'\n",
    "else:\n",
    "    device = 'cpu'\n",
    "device = torch.device(device)\n",
    "print(\"You are using device: %s\" % device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_output = torch.rand((5, 320, 20)).to(device) # N, input_size, T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Decoder import Decoder\n",
    "from PostNet import PostNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 256, 20])\n",
      "tensor([[[ 0.0049,  0.0212, -0.0038,  ..., -0.0357, -0.0692, -0.0574],\n",
      "         [-0.0401, -0.0437, -0.0136,  ...,  0.0015, -0.0009,  0.0054],\n",
      "         [ 0.0180, -0.0018, -0.0139,  ...,  0.0046,  0.0354, -0.0194],\n",
      "         ...,\n",
      "         [ 0.0125,  0.0148,  0.0717,  ...,  0.0401,  0.0533,  0.0581],\n",
      "         [ 0.0380,  0.0231,  0.0695,  ..., -0.0339, -0.0103,  0.0286],\n",
      "         [ 0.0029,  0.0173,  0.0301,  ...,  0.0196,  0.0051, -0.0239]],\n",
      "\n",
      "        [[-0.0362, -0.0336, -0.0326,  ..., -0.0140, -0.0367, -0.0419],\n",
      "         [ 0.0271,  0.0553,  0.0397,  ...,  0.0463,  0.0378,  0.0515],\n",
      "         [ 0.0624,  0.0914,  0.0804,  ...,  0.0506,  0.0346, -0.0216],\n",
      "         ...,\n",
      "         [ 0.0305,  0.0502,  0.0677,  ...,  0.0088,  0.0577,  0.0511],\n",
      "         [ 0.0214, -0.0062,  0.0041,  ...,  0.0028,  0.0246,  0.0548],\n",
      "         [ 0.0028,  0.0415,  0.0725,  ...,  0.0605,  0.0695,  0.0339]],\n",
      "\n",
      "        [[-0.0173, -0.0301, -0.0227,  ..., -0.0217, -0.0529, -0.0655],\n",
      "         [-0.0011,  0.0349,  0.0165,  ...,  0.0231,  0.0223,  0.0132],\n",
      "         [ 0.0176,  0.0123,  0.0263,  ...,  0.0376,  0.0234,  0.0115],\n",
      "         ...,\n",
      "         [ 0.0265,  0.0895,  0.0830,  ...,  0.0094,  0.0470,  0.0423],\n",
      "         [-0.0025,  0.0247,  0.0248,  ...,  0.0187, -0.0132,  0.0268],\n",
      "         [ 0.0078,  0.0490,  0.0694,  ...,  0.0974,  0.0545,  0.0217]],\n",
      "\n",
      "        [[-0.0253, -0.0170,  0.0222,  ..., -0.0265, -0.0219, -0.0476],\n",
      "         [ 0.0006,  0.0297,  0.0340,  ...,  0.0159, -0.0091, -0.0100],\n",
      "         [ 0.0535,  0.0969,  0.0342,  ...,  0.0544,  0.0449,  0.0430],\n",
      "         ...,\n",
      "         [ 0.0218,  0.1123,  0.1201,  ...,  0.0232,  0.0545,  0.0876],\n",
      "         [-0.0126,  0.0072,  0.0335,  ..., -0.0244, -0.0085,  0.0305],\n",
      "         [ 0.0215,  0.0504,  0.0837,  ...,  0.0617,  0.0332,  0.0040]],\n",
      "\n",
      "        [[-0.0259,  0.0134, -0.0262,  ...,  0.0169, -0.0157,  0.0029],\n",
      "         [ 0.0229,  0.0353,  0.0322,  ...,  0.0035, -0.0162, -0.0435],\n",
      "         [ 0.0245,  0.0121,  0.0211,  ...,  0.0461,  0.0565,  0.0271],\n",
      "         ...,\n",
      "         [ 0.0368,  0.0734,  0.0614,  ..., -0.0240,  0.0099,  0.0222],\n",
      "         [ 0.0357,  0.0088,  0.0162,  ...,  0.0308,  0.0070,  0.0260],\n",
      "         [ 0.0342,  0.0854,  0.0906,  ...,  0.0564,  0.0471,  0.0329]]],\n",
      "       device='mps:0', grad_fn=<TransposeBackward0>)\n"
     ]
    }
   ],
   "source": [
    "decoder = Decoder(lstm_bidirectional=True).to(device)\n",
    "decoder_output = decoder.forward(encoder_output)\n",
    "print(decoder_output.shape) # N, output_size, T\n",
    "print(decoder_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "linear(): input and weight.T shapes cannot be multiplied (256x20 and 256x256)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m postnet \u001b[38;5;241m=\u001b[39m PostNet()\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m----> 2\u001b[0m postnet_output \u001b[38;5;241m=\u001b[39m \u001b[43mpostnet\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdecoder_output\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(postnet_output\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;66;03m# (N, output size, T)\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(postnet_output)\n",
      "File \u001b[0;32m~/Documents/Voice-to-Song-DL-Final/PostNet.py:119\u001b[0m, in \u001b[0;36mPostNet.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_layers):\n\u001b[1;32m    117\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactivation(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcnn_set[i](outputs)) \u001b[38;5;66;03m# (N, Hidden Size, T)\u001b[39;00m\n\u001b[0;32m--> 119\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;66;03m#############################################################################\u001b[39;00m\n\u001b[1;32m    122\u001b[0m \u001b[38;5;66;03m#                              END OF YOUR CODE                             #\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;66;03m#############################################################################\u001b[39;00m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/cs7643-finalproject-v2/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/cs7643-finalproject-v2/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/cs7643-finalproject-v2/lib/python3.10/site-packages/torch/nn/modules/linear.py:117\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: linear(): input and weight.T shapes cannot be multiplied (256x20 and 256x256)"
     ]
    }
   ],
   "source": [
    "postnet = PostNet().to(device)\n",
    "postnet_output = postnet.forward(decoder_output)\n",
    "print(postnet_output.shape) # (N, output size, T)\n",
    "print(postnet_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 80, 1])\n",
      "torch.Size([5, 320, 20])\n",
      "torch.Size([5, 80, 20])\n",
      "torch.Size([5, 80, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/cs7643-finalproject-v2/lib/python3.10/site-packages/torch/nn/modules/loss.py:538: UserWarning: Using a target size (torch.Size([5, 80, 20])) that is different to the input size (torch.Size([5, 80, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.7716, device='mps:0', grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loss Test\n",
    "from utils import criterion\n",
    "#\n",
    "input = torch.rand((5, 80, 1)).to(device)\n",
    "\n",
    "print(input.shape)\n",
    "print(encoder_output.shape)\n",
    "print(decoder_output.shape)\n",
    "print(postnet_output.shape)\n",
    "\n",
    "criterion(input=input, encoder_ouput=encoder_output, decoder_output=decoder_output, postnet_output=postnet_output, encoded_postnet_output=encoder_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training, evaluation, and plotting loss curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code provide to you for training and evaluation\n",
    "from utils import train\n",
    "from utils import evaluate\n",
    "from utils import plot_curves\n",
    "from Model import Model\n",
    "\n",
    "def train_and_plot(model, optimizer, scheduler, criterion, train_loader, valid_loader, filename, epochs, device='cpu'):\n",
    "    train_loss_history = []\n",
    "    valid_loss_history = []\n",
    "\n",
    "    for epoch_idx in range(epochs):\n",
    "        print(\"-----------------------------------\")\n",
    "        print(\"Epoch %d\" % (epoch_idx+1))\n",
    "        print(\"-----------------------------------\")\n",
    "\n",
    "        train_loss, avg_train_loss = train(model, train_loader, optimizer, criterion, device=device)\n",
    "        scheduler.step(train_loss)\n",
    "\n",
    "        val_loss, avg_val_loss = evaluate(model, valid_loader, criterion, device=device)\n",
    "\n",
    "        train_loss_history.append(avg_train_loss)\n",
    "        valid_loss_history.append(avg_val_loss)\n",
    "\n",
    "        print(\"Training Loss: %.4f. Validation Loss: %.4f.\" % (avg_train_loss, avg_val_loss))\n",
    "\n",
    "    plot_curves(train_loss_history, valid_loss_history, filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Example usage:\n",
    "model = Model()\n",
    "train_loader = DataLoader(your_train_dataset, batch_size=32, shuffle=True)\n",
    "valid_loader = DataLoader(your_valid_dataset, batch_size=32, shuffle=False)\n",
    "optimizer = Adam(model.parameters(), lr=1e-3)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min')\n",
    "criterion = criterion(input=input, encoder_ouput=encoder_output, decoder_output=decoder_output, postnet_output=postnet_output, encoded_postnet_output=encoder_output)\n",
    "filename = \"training_loss_curves\"\n",
    "epochs = 10\n",
    "# device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "train_and_plot(model, optimizer, scheduler, criterion, train_loader, valid_loader, filename, epochs, device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.19 ('cs7643-finalproject')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "vscode": {
   "interpreter": {
    "hash": "b318cc0a9b93c728b3b7b65ea17418aadcbb887a11db4ac09395b12b554738da"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
