{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just run this block. Please do not modify the following code.\n",
    "import math\n",
    "import time\n",
    "import io\n",
    "import numpy as np\n",
    "import csv\n",
    "from IPython.display import Image\n",
    "\n",
    "# Pytorch package\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Torchtest package\n",
    "# import torchtext\n",
    "# from torchtext.datasets import Multi30k\n",
    "from torch.utils.data import DataLoader\n",
    "# from torchtext.data.utils import get_tokenizer\n",
    "from collections import Counter\n",
    "# from torchtext.vocab import vocab\n",
    "# from torchtext.utils import download_from_url, extract_archive\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.optim import Adam\n",
    "\n",
    "# Tqdm progress bar\n",
    "from tqdm import tqdm_notebook, tqdm\n",
    "\n",
    "# Code provide to you for training and evaluation\n",
    "\n",
    "# for auto-reloading external modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "torch.seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check device availability\n",
    "device = ''\n",
    "if torch.cuda.is_available():\n",
    "    device = 'cuda'\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = 'mps'\n",
    "else:\n",
    "    device = 'cpu'\n",
    "device = torch.device(device)\n",
    "print(\"You are using device: %s\" % device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training, evaluation, and plotting loss curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code provide to you for training and evaluation\n",
    "from utils_experiment2 import train\n",
    "from utils_experiment2 import evaluate\n",
    "from utils_experiment2 import plot_curves\n",
    "from Model import Model\n",
    "\n",
    "def train_and_plot(model, optimizer, scheduler, criterion, train_loader, valid_loader, filename, epochs, device='cpu'):\n",
    "    train_loss_history = []\n",
    "    valid_loss_history = []\n",
    "\n",
    "    for epoch_idx in range(epochs):\n",
    "        print(\"-----------------------------------\")\n",
    "        print(\"Epoch %d\" % (epoch_idx+1))\n",
    "        print(\"-----------------------------------\")\n",
    "\n",
    "        train_loss, avg_train_loss = train(model, train_loader, optimizer, criterion, device=device)\n",
    "        scheduler.step(train_loss)\n",
    "\n",
    "        val_loss, avg_val_loss = evaluate(model, valid_loader, criterion, device=device)\n",
    "\n",
    "        train_loss_history.append(avg_train_loss)\n",
    "        valid_loss_history.append(avg_val_loss)\n",
    "\n",
    "        print(\"Training Loss: %.4f. Validation Loss: %.4f.\" % (avg_train_loss, avg_val_loss))\n",
    "\n",
    "    plot_curves(train_loss_history, valid_loss_history, filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import preppedData \n",
    "import numpy as np\n",
    "# Example usage:\n",
    "model = Model().to(device)\n",
    "\n",
    "\n",
    "model.load_state_dict(torch.load('model_final_e2.pt'),strict=False)\n",
    "\n",
    "spec = np.load('./spectrograms_v2.npy')\n",
    "style = np.load('sing_resemblyzer_vectors_v2.npy')\n",
    "target = np.load('speech_resemblyzer_vectors.npy')\n",
    "\n",
    "spec = np.transpose(spec,(0,2,1))#use if the dataset is not already transposed\n",
    "print(spec.shape)\n",
    "style = style[0:spec.shape[0],:]\n",
    "target = np.concatenate((target,target),axis=0)\n",
    "print(target.shape)\n",
    "dataList = []\n",
    "\n",
    "style = style[0:target.shape[0],:]\n",
    "\n",
    "spec = spec[0:target.shape[0],:,:]\n",
    "\n",
    "for i in range(0,spec.shape[0]):\n",
    "    dataList.append((spec[i,:,:],style[i,:],target[i,:]))\n",
    "\n",
    "print(len(dataList))\n",
    "\n",
    "print(dataList[0][0].shape)\n",
    "print(dataList[0][1].shape)\n",
    "print(dataList[0][2].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2145\n",
      "2145\n",
      "536\n",
      "(256, 692)\n"
     ]
    }
   ],
   "source": [
    "from utils_experiment2 import criterion\n",
    "\n",
    "\n",
    "pct_2_use = 0.5\n",
    "train_pct = 0.8\n",
    "\n",
    "chunk_end = int(len(dataList)*pct_2_use)\n",
    "\n",
    "train_end_ind = int(round(chunk_end*train_pct,0))\n",
    "\n",
    "print(train_end_ind)\n",
    "\n",
    "your_train_dataset = dataList[0:train_end_ind]\n",
    "\n",
    "your_valid_dataset = dataList[train_end_ind:chunk_end]\n",
    "print(len(your_train_dataset))\n",
    "print(len(your_valid_dataset))\n",
    "print(your_train_dataset[0][0].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------\n",
      "Epoch 1\n",
      "-----------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/429 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "reconstruct() takes from 3 to 4 positional arguments but 5 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 10\u001b[0m\n\u001b[0;32m      7\u001b[0m epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# device = 'cuda' if torch.cuda.is_available() else 'cpu'\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m \u001b[43mtrain_and_plot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalid_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[3], line 16\u001b[0m, in \u001b[0;36mtrain_and_plot\u001b[1;34m(model, optimizer, scheduler, criterion, train_loader, valid_loader, filename, epochs, device)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (epoch_idx\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-----------------------------------\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 16\u001b[0m train_loss, avg_train_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m scheduler\u001b[38;5;241m.\u001b[39mstep(train_loss)\n\u001b[0;32m     19\u001b[0m val_loss, avg_val_loss \u001b[38;5;241m=\u001b[39m evaluate(model, valid_loader, criterion, device\u001b[38;5;241m=\u001b[39mdevice)\n",
      "File \u001b[1;32mc:\\Users\\baseb\\OneDrive\\Desktop\\Spring 2024 Classes\\DL\\Project\\Voice-to-Song-DL-Final\\utils_experiment2.py:92\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, dataloader, optimizer, criterion, device)\u001b[0m\n\u001b[0;32m     90\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m     91\u001b[0m spec, encoder_out, decoder_out, postnet_out, encoded_postnet_out \u001b[38;5;241m=\u001b[39m model((singing_spec, speech_style,target))\n\u001b[1;32m---> 92\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mcriterion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mspec\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoder_out\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecoder_out\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpostnet_out\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoded_postnet_out\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m#edited to unpack multiple returns\u001b[39;00m\n\u001b[0;32m     93\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m     94\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[1;32mc:\\Users\\baseb\\OneDrive\\Desktop\\Spring 2024 Classes\\DL\\Project\\Voice-to-Song-DL-Final\\utils_experiment2.py:40\u001b[0m, in \u001b[0;36mcriterion\u001b[1;34m(input, encoder_ouput, decoder_output, postnet_output, encoded_postnet_output, in_style, gamma)\u001b[0m\n\u001b[0;32m     38\u001b[0m detached \u001b[38;5;241m=\u001b[39m detached\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     39\u001b[0m \u001b[38;5;66;03m# Reconstruct waveforms from the batch of magnitude spectrograms\u001b[39;00m\n\u001b[1;32m---> 40\u001b[0m reconstructed_waveforms \u001b[38;5;241m=\u001b[39m \u001b[43mvocoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreconstruct\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdetached\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m44100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     41\u001b[0m ve \u001b[38;5;241m=\u001b[39m VoiceEncoder(device\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     42\u001b[0m styles \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[1;31mTypeError\u001b[0m: reconstruct() takes from 3 to 4 positional arguments but 5 were given"
     ]
    }
   ],
   "source": [
    "\n",
    "train_loader = DataLoader(your_train_dataset, batch_size=5, shuffle=True)\n",
    "valid_loader = DataLoader(your_valid_dataset, batch_size=5, shuffle=False)\n",
    "optimizer = Adam(model.parameters(), lr=5e-4)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min')\n",
    "criterion = criterion\n",
    "filename = \"training_loss_curves\"\n",
    "epochs = 1\n",
    "# device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "train_and_plot(model, optimizer, scheduler, criterion, train_loader, valid_loader, filename, epochs, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(),'model_final_e2_w_styleV2.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.19 ('cs7643-finalproject')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "vscode": {
   "interpreter": {
    "hash": "b318cc0a9b93c728b3b7b65ea17418aadcbb887a11db4ac09395b12b554738da"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
